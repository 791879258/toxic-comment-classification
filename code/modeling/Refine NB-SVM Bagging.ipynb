{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from functools import partial\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "FILE_DIR = '../../input'\n",
    "\n",
    "# create label matrix\n",
    "train = pd.read_csv(f'{FILE_DIR}/train.csv')\n",
    "class_list = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "Y = train[class_list].values\n",
    "\n",
    "# load features \n",
    "X = sparse.hstack([\n",
    "    sparse.load_npz(f'{FILE_DIR}/tfidf/train_clean0_char_tfidf.npz'),\n",
    "    sparse.load_npz(f'{FILE_DIR}/tfidf/train_clean0_word_tfidf.npz'),\n",
    "    sparse.load_npz(f'{FILE_DIR}/tfidf/train_clean0_pos_tfidf.npz'),\n",
    "]).tocsr()\n",
    "\n",
    "X_test = sparse.hstack([\n",
    "    sparse.load_npz(f'{FILE_DIR}/tfidf/test_clean0_char_tfidf.npz'),\n",
    "    sparse.load_npz(f'{FILE_DIR}/tfidf/test_clean0_word_tfidf.npz'),\n",
    "    sparse.load_npz(f'{FILE_DIR}/tfidf/test_clean0_pos_tfidf.npz'),\n",
    "]).tocsr()\n",
    "\n",
    "# optimal parameters\n",
    "nbsvm_log = pd.read_csv(f'{FILE_DIR}/logs/nbsvm100000_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbsvm_eval(it, j, train_index, valid_index, alpha, beta):\n",
    "    gc.collect()\n",
    "    \n",
    "    # subset data\n",
    "    X_train, y_train = X[train_index], Y[train_index, j]\n",
    "    X_valid, y_valid = X[valid_index], Y[valid_index, j]\n",
    "        \n",
    "    # boostrap sampling\n",
    "    np.random.seed(it)\n",
    "    bag_indexs = np.random.randint(X_train.shape[0], size=X_train.shape[0])\n",
    "    X_bag, y_bag = X_train[bag_indexs], y_train[bag_indexs]\n",
    "\n",
    "    # get NB weights\n",
    "    smooth = 10**alpha\n",
    "    p = smooth + X_bag[y_bag==1].sum(0)\n",
    "    q = smooth + X_bag[y_bag==0].sum(0)\n",
    "    w = np.log((p/np.sum(p))/(q/np.sum(q)))  \n",
    "    \n",
    "    # create features\n",
    "    valid_features = X_valid.multiply(w)\n",
    "    test_features = X_test.multiply(w)\n",
    "    bag_features = X_bag.multiply(w)\n",
    "\n",
    "    # fit model on training data\n",
    "    f = LogisticRegression(dual=True, C=10**beta)\n",
    "    f.fit(bag_features, y_bag)\n",
    "\n",
    "    # make predictions on validation and test data\n",
    "    return (f.predict_proba(valid_features)[:,1],\n",
    "            f.predict_proba(test_features)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create storage containers\n",
    "n_folds, n_bags, seed = 10, 5, 0\n",
    "oof_preds = np.zeros(Y.shape)\n",
    "test_preds = np.zeros((X_test.shape[0], 6))\n",
    "\n",
    "for j, class_name in enumerate(class_list):\n",
    "\n",
    "    # unpack parameters\n",
    "    class_params = nbsvm_log[nbsvm_log['class_name']==class_name]\n",
    "    alpha = class_params['alpha'].values[0]\n",
    "    beta = class_params['beta'].values[0]\n",
    "        \n",
    "    kf = KFold(n_splits=n_folds, random_state=seed)\n",
    "    for k, (train_index, valid_index) in enumerate(kf.split(X)):\n",
    "        print(f'[{k:02}] {class_name}:  ', end='')\n",
    "        \n",
    "        # bagging\n",
    "        start_time = time.time()\n",
    "        nbsvm_bag = partial(nbsvm_eval, j=j,\n",
    "                            train_index=train_index,\n",
    "                            valid_index=valid_index,\n",
    "                            alpha=alpha,\n",
    "                            beta=beta)\n",
    "        pool = multiprocessing.Pool(5)\n",
    "        bag_preds = pool.map(nbsvm_bag, range(n_bags))\n",
    "        pool.terminate()        \n",
    "        \n",
    "        # unpack predictions\n",
    "        bag_auc = []\n",
    "        for oof_bag_preds, test_bag_preds in bag_preds:\n",
    "            oof_preds[valid_index,j] += oof_bag_preds\n",
    "            test_preds[:,j] += test_bag_preds/n_bags/n_folds\n",
    "            bag_auc.append(roc_auc_score(Y[valid_index,j], oof_bag_preds))\n",
    "            \n",
    "        print(f'auc: {np.mean(bag_auc):0.5f}  time: {(time.time()-start_time)/60:02.02f} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-fold predictions\n",
    "save_name = f'{FILE_DIR}/out_of_fold_preds/nbsvm_bags{n_bags}_validation_seed{seed}.csv'\n",
    "pd.DataFrame(oof_preds, columns=class_list).to_csv(save_name)\n",
    "\n",
    "# test set predictions\n",
    "save_name = f'{FILE_DIR}/submissions/aggregate/nbsvm_bags{n_bags}_seed{seed}.csv'\n",
    "subm = pd.read_csv(f'{FILE_DIR}/sample_submission.csv')\n",
    "for j, class_name in enumerate(class_list):\n",
    "    subm[class_name] = test_preds[:,j]\n",
    "subm.to_csv(save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
